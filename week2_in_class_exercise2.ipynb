{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhicNeMz4afD"
      },
      "source": [
        "# **RL In-Class Exercise 2 Tutorial 2**\n",
        "This notebook contains the in-class exercise 2 from tutorial 2 of Deep Reinforcement Learning in AML."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6KRFo0DTgRI"
      },
      "source": [
        "# Exercise Overview\n",
        "\n",
        "In the first in-class exercise, you implemented Actor-Critic. Now you'll extend it to PPO!\n",
        "\n",
        "## What changes from Actor-Critic to PPO?\n",
        "\n",
        "### Main differences:\n",
        "1. **Clipped surrogate objective:** Prevent destructive policy updates\n",
        "2. **Multiple epochs on same data:** Reuse collected experience\n",
        "3. **Mini-batch updates:** Both actor and critic update together\n",
        "4. **Entropy regularization:** Encourage exploration\n",
        "\n",
        "### Exercises:\n",
        "\n",
        "**Exercise 1:** Implement `get_log_prob()` - Extract log probability computation\n",
        "\n",
        "**Exercise 2:** Implement `get_actor_loss()` - PPO clipped surrogate loss with entropy\n",
        "\n",
        "**Exercise 3:** Modify `train_one_epoch()` - Mini-batches and multiple epochs\n",
        "\n",
        "**Exercise 4:** Modify the training cell - Add PPO hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vrcXPde4Tcs"
      },
      "source": [
        "# Install & Import Requirements\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rrswUBWbwgYC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: swig in /home/lamberto/.local/lib/python3.10/site-packages (4.4.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: gymnasium[box2d] in /home/lamberto/.local/lib/python3.10/site-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /home/lamberto/.local/lib/python3.10/site-packages (from gymnasium[box2d]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /home/lamberto/.local/lib/python3.10/site-packages (from gymnasium[box2d]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /home/lamberto/.local/lib/python3.10/site-packages (from gymnasium[box2d]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /home/lamberto/.local/lib/python3.10/site-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /home/lamberto/.local/lib/python3.10/site-packages (from gymnasium[box2d]) (2.3.5)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /home/lamberto/.local/lib/python3.10/site-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Requirement already satisfied: swig==4.* in /home/lamberto/.local/lib/python3.10/site-packages (from gymnasium[box2d]) (4.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install swig\n",
        "!pip install gymnasium[box2d]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vSTbNBUqvggp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lamberto/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
            "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions.normal import Normal\n",
        "from torch.optim import Adam\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from typing import Sequence\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CQCDS-pTWa8"
      },
      "source": [
        "# Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swI8tn4Z4jgh"
      },
      "source": [
        "## MLP function to create the policy network of our agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e9lecbV0xuQY"
      },
      "outputs": [],
      "source": [
        "def mlp(sizes: Sequence[int], activation=nn.ReLU, output_activation=nn.Identity) -> nn.Sequential:\n",
        "  \"\"\"\n",
        "      Create a simple feedforward neural network.\n",
        "  \"\"\"\n",
        "  layers = []\n",
        "  for j in range(len(sizes)-1):\n",
        "    act = activation if j < len(sizes)-2 else output_activation\n",
        "    layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
        "  return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2ADMYKA4vmK"
      },
      "source": [
        "## Functions to get the ouput of the policy network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7znaERjC2lwZ"
      },
      "outputs": [],
      "source": [
        "def get_policy(obs: torch.Tensor) -> Normal:\n",
        "  \"\"\"\n",
        "  Get the stochastic policy for a given observation (-batch).\n",
        "  Returns a distribution for every action-dimension.\n",
        "  \"\"\"\n",
        "  obs = obs.unsqueeze(0) if obs.dim() == 1 else obs  # for single observations that do not have a batch dimension\n",
        "  logits = actor(obs)\n",
        "  mean, logstd = logits[:, :n_acts], logits[:, n_acts:]  # split the output layer into mean and logstd\n",
        "  logstd = torch.clamp(logstd, min=-20, max=2)  # for numerical stability\n",
        "  return Normal(mean, torch.exp(logstd))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "K-f7TYWJ2nDo"
      },
      "outputs": [],
      "source": [
        "def get_action(obs: torch.Tensor) -> np.ndarray:\n",
        "  \"\"\"\n",
        "  Get the action (-batch) from the policy for a given observation (-batch).\n",
        "  \"\"\"\n",
        "  dist = get_policy(obs)\n",
        "  return dist.sample().squeeze(0).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gUrD7azUQ9J"
      },
      "source": [
        "## EXERCISE 1: Implement get_log_prob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7pSoO8tUekq"
      },
      "source": [
        "In PPO, we need to compute log probabilities separately for importance sampling.\n",
        "\n",
        "This function extracts the log probability computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Lv3Tj8j1UZof"
      },
      "outputs": [],
      "source": [
        "def get_log_prob(obs: torch.Tensor, act: torch.Tensor) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  Get the log-probability of a given action for a given observation.\n",
        "\n",
        "  Args:\n",
        "      obs: Observations tensor of shape (batch_size, obs_dim)\n",
        "      act: Actions tensor of shape (batch_size, n_acts)\n",
        "\n",
        "  Returns:\n",
        "      log_probs: Log probabilities of shape (batch_size,)\n",
        "  \"\"\"\n",
        "  dist = get_policy(obs)\n",
        "  probs = dist.log_prob(act).sum(dim=-1)\n",
        "  return probs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR3xJqSvU73y"
      },
      "source": [
        "### Test Functions (Feel free to collapse this cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "28TZGNvUVGUm"
      },
      "outputs": [],
      "source": [
        "def test_get_log_prob(get_log_prob_fn):\n",
        "    \"\"\"\n",
        "    Test the get_log_prob implementation.\n",
        "    \"\"\"\n",
        "    # Create dummy actor network for testing\n",
        "    global actor, n_acts\n",
        "    n_acts = 2\n",
        "    actor = mlp([8] + [64, 64] + [2*n_acts])\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Test 1: Output has correct shape\n",
        "    try:\n",
        "        obs = torch.randn(10, 8)\n",
        "        act = torch.randn(10, 2)\n",
        "\n",
        "        log_probs = get_log_prob_fn(obs, act)\n",
        "\n",
        "        if log_probs.shape == torch.Size([10]):\n",
        "            print(\"âœ“ Test 1: Output shape correct\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(f\"âœ— Test 1: Output shape should be (10,)\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 1: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    # Test 2: Output dtype is correct\n",
        "    try:\n",
        "        obs = torch.randn(10, 8)\n",
        "        act = torch.randn(10, 2)\n",
        "\n",
        "        log_probs = get_log_prob_fn(obs, act)\n",
        "\n",
        "        if log_probs.dtype == torch.float32:\n",
        "            print(\"âœ“ Test 2: Output dtype correct\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(f\"âœ— Test 2: Output dtype should be float32\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 2: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    # Test 3: Different actions produce different log probs\n",
        "    try:\n",
        "        torch.manual_seed(42)\n",
        "        obs = torch.randn(10, 8)\n",
        "        act1 = torch.randn(10, 2)\n",
        "        act2 = torch.randn(10, 2)\n",
        "\n",
        "        log_probs1 = get_log_prob_fn(obs, act1)\n",
        "        log_probs2 = get_log_prob_fn(obs, act2)\n",
        "\n",
        "        if not torch.allclose(log_probs1, log_probs2):\n",
        "            print(\"âœ“ Test 3: Different actions produce different log probs\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(\"âœ— Test 3: Different actions should produce different log probs\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 3: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    # Test 4: Works with single observation\n",
        "    try:\n",
        "        obs = torch.randn(1, 8)\n",
        "        act = torch.randn(1, 2)\n",
        "\n",
        "        log_probs = get_log_prob_fn(obs, act)\n",
        "\n",
        "        if log_probs.shape == torch.Size([1]):\n",
        "            print(\"âœ“ Test 4: Works with single observation\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(\"âœ— Test 4: Should work with single observation\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 4: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    return sum(results), len(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGWninDCVNJH"
      },
      "source": [
        "### Run Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "q0hZnFFxVRBR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Test 1: Output shape correct\n",
            "âœ“ Test 2: Output dtype correct\n",
            "âœ“ Test 3: Different actions produce different log probs\n",
            "âœ“ Test 4: Works with single observation\n",
            "\n",
            "==================================================\n",
            "Results: 4/4 tests passed\n",
            "ðŸŽ‰ All tests passed! You're ready to move on.\n"
          ]
        }
      ],
      "source": [
        "passed, total = test_get_log_prob(get_log_prob)\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"Results: {passed}/{total} tests passed\")\n",
        "if passed == total:\n",
        "  print(\"ðŸŽ‰ All tests passed! You're ready to move on.\")\n",
        "else:\n",
        "  print(\"âš ï¸  Some tests failed. Review your implementation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQcwOGwq3iu2"
      },
      "source": [
        "## Function to compute GAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rGa1xIfn3nAX"
      },
      "outputs": [],
      "source": [
        "def compute_gae(rewards: torch.Tensor,\n",
        "                values: torch.Tensor,\n",
        "                next_values: torch.Tensor,\n",
        "                dones: torch.Tensor,  # values are either 1.0 (has ended) or 0.0 (has not ended), indicating whether an episode has ended or not.\n",
        "                gamma=0.99,  # discount factor (0,1]\n",
        "                lam=0.95,  # trace-decay parameter [0,1]. lam=0.0: temporal difference, lam=1.0: Monte Carlo\n",
        "                ) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  Compute the Generalized Advantage Estimation (GAE) used for the actor loss function.\n",
        "  Balances the bias-variance tradeoff of the advantage estimates.\n",
        "  lam=0.0: temporal difference, high bias - low variance\n",
        "  lam=1.0: Monte Carlo, high variance - low bias\n",
        "  \"\"\"\n",
        "  T = rewards.shape[0]\n",
        "  advantages = torch.zeros_like(rewards)\n",
        "  gae = 0.0\n",
        "  for t in reversed(range(T)):\n",
        "    nonterminal = 1.0 - dones[t]\n",
        "    delta = rewards[t] + gamma * next_values[t] * nonterminal - values[t]\n",
        "    gae = delta + gamma * lam * nonterminal * gae\n",
        "    advantages[t] = gae\n",
        "  return advantages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKMwBRCmTBSm"
      },
      "source": [
        "## EXERCISE 2: Modify get_actor_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvqbfILFV04J"
      },
      "source": [
        "PPO uses a clipped surrogate objective instead of vanilla policy gradient.\n",
        "\n",
        "Key components:\n",
        "1. Importance sampling ratio (for numerical stability we first calclate the log of the ratio)\n",
        "2. Clipped ratio: prevents ratio from going too far from 1.0\n",
        "3. Clipped objective\n",
        "4. Entropy bonus: encourages exploration\n",
        "\n",
        "You need to implement all of these components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cAzIijKr2okX"
      },
      "outputs": [],
      "source": [
        "def get_actor_loss(obs: torch.Tensor, act: torch.Tensor, weights: torch.Tensor, old_logp: torch.Tensor, beta: float=0.00) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  Compute the PPO clipped surrogate loss with entropy regularization for the actor.\n",
        "\n",
        "  Args:\n",
        "        obs: Observations tensor of shape (batch_size, obs_dim)\n",
        "        act: Actions tensor of shape (batch_size, n_acts)\n",
        "        weights: Advantage estimates of shape (batch_size,)\n",
        "        old_logp: Log probabilities under old policy of shape (batch_size,)\n",
        "        beta: Entropy regularization coefficient\n",
        "\n",
        "    Returns:\n",
        "        loss: Scalar loss tensor\n",
        "  \"\"\"\n",
        "  dist = get_policy(obs)\n",
        "  logp = get_log_prob(obs,act)\n",
        "  # NOTE: Make importance weight\n",
        "  ratio = torch.exp(logp - old_logp)\n",
        "  # NOTE: In this case the weights are the advantages, should be negative but we handle in the return \n",
        "  clipped_obj = torch.min(ratio* weights, torch.clamp(ratio, 1- clip_ratio, 1+ clip_ratio) * weights).mean()\n",
        "  entropy = dist.entropy().sum(dim=-1).mean()\n",
        "  return - clipped_obj - beta*entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cd8wVqKNTGuy"
      },
      "source": [
        "## Function to compute the discounted return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4oyDxrHn2q_v"
      },
      "outputs": [],
      "source": [
        "def discounted_return(arr: Sequence[float], gamma=0.99) -> list[float]:\n",
        "  \"\"\"\n",
        "  Compute the discounted return for a single episode, given a sequence of rewards.\n",
        "  gamma: discount factor (0,1]\n",
        "  Used for the MSE loss function of the critic.\n",
        "  \"\"\"\n",
        "  ret = [0.0] * len(arr)\n",
        "  ret[-1] = arr[-1]\n",
        "  for i in range(len(arr)-2, -1, -1):\n",
        "    ret[i] = arr[i] + gamma * ret[i+1]\n",
        "  return ret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bao0HIiTKyq"
      },
      "source": [
        "## EXERCISE 3: Modify train_one_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqQVo_TOXZJ5"
      },
      "source": [
        "PPO makes several key changes to Actor-Critic's training:\n",
        "\n",
        "1. Compute old_log_prob BEFORE any updates (for importance sampling)\n",
        "2. Remove separate critic update loop\n",
        "3. Add outer loop for multiple epochs (n_ppo_epochs)\n",
        "4. Add inner loop for mini-batches with shuffling\n",
        "5. Both actor and critic update in each mini-batch\n",
        "6. Add gradient clipping for stability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "B36ehZOx2zyQ"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch() -> tuple[list, list]:\n",
        "  \"\"\"\n",
        "  Train the actor and critic for one epoch,\n",
        "  i.e. one actor-update and n_critic_updates critic-updates.\n",
        "  \"\"\"\n",
        "  batch_obs = []\n",
        "  batch_acts = []\n",
        "  batch_rewards = []\n",
        "  batch_next_obs = []\n",
        "  batch_dones = []\n",
        "  batch_rets = []\n",
        "  batch_lens = []\n",
        "  batch_Rtogo = []\n",
        "\n",
        "  obs, _ = env.reset()\n",
        "  ep_rews = []\n",
        "\n",
        "\n",
        "  while True:\n",
        "    act = get_action(torch.as_tensor(obs, dtype=torch.float32))\n",
        "    next_obs, rew, terminated, truncated, _ = env.step(act)\n",
        "    done = terminated or truncated\n",
        "\n",
        "    batch_obs.append(obs.copy())  # copy as obs is modified in-place\n",
        "    batch_acts.append(act)  # act is newly initialized every loop -> no copy\n",
        "    batch_rewards.append(rew)\n",
        "    batch_next_obs.append(next_obs.copy())\n",
        "    batch_dones.append(done)\n",
        "    ep_rews.append(rew)\n",
        "\n",
        "    obs = next_obs\n",
        "\n",
        "    if done:\n",
        "      batch_rets.append(sum(ep_rews))\n",
        "      batch_lens.append(len(ep_rews))\n",
        "      batch_Rtogo += discounted_return(ep_rews, gamma=gamma)\n",
        "      ep_rews = []\n",
        "      obs, _ = env.reset()\n",
        "\n",
        "      if len(batch_obs) > batch_size:\n",
        "        break\n",
        "\n",
        "  # convert lists to tensors\n",
        "  batch_obs = torch.as_tensor(np.array(batch_obs), dtype=torch.float32)\n",
        "  batch_next_obs = torch.as_tensor(np.array(batch_next_obs), dtype=torch.float32)\n",
        "  batch_acts = torch.as_tensor(np.array(batch_acts), dtype=torch.float32)\n",
        "  batch_rewards = torch.as_tensor(np.array(batch_rewards), dtype=torch.float32)\n",
        "  batch_dones = torch.as_tensor(np.array(batch_dones), dtype=torch.float32)\n",
        "  batch_Rtogo = torch.as_tensor(np.array(batch_Rtogo), dtype=torch.float32)\n",
        "\n",
        "  V_target = batch_Rtogo.detach()  # target for critic, cannot have gradients\n",
        "\n",
        "  # TODO: Remove the critic update here\n",
        "  # DONE\n",
        "\n",
        "  # calculate generalized advantage estimate GAE\n",
        "  with torch.no_grad():  # advantages should never have gradients\n",
        "    value = critic(batch_obs).squeeze()\n",
        "    next_values = critic(batch_next_obs).squeeze()\n",
        "    A_gae = compute_gae(batch_rewards, value, next_values, batch_dones, gamma=gamma, lam=lam)  # weight for actor loss function\n",
        "  A_gae = ((A_gae - A_gae.mean()) / (A_gae.std() + 1e-8))\n",
        "\n",
        "  # TODO: Remove the actor update here\n",
        "  # DONE\n",
        "\n",
        "  # TODO: Compute old_log_prob before any updates (for importance sampling)\n",
        "  old_log_prob = get_log_prob(batch_obs,batch_acts).detach()\n",
        "\n",
        "  # TODO: Add outer loop for multiple epochs (use n_ppo_epochs)\n",
        "  # TODO: Inside outer loop, shuffle the data\n",
        "  # Hint: Use torch.randperm(len(batch_obs)) to get shuffled indices\n",
        "  for _ in range(n_ppo_epochs):\n",
        "    indices = torch.randperm(len(batch_obs))\n",
        "\n",
        "    # TODO: Add inner loop for mini-batches\n",
        "    # Hint: Loop from 0 to len(batch_obs) with step size mini_batch_size\n",
        "    # Hint: Get mini-batch indices: idx = indices[start:end]\n",
        "    # Hint: Check if idx is not empty before processing\n",
        "    for start in range(0,len(batch_obs),mini_batch_size):\n",
        "      end = min(start + mini_batch_size, len(batch_obs))\n",
        "      idx = indices[start:end]\n",
        "      if len(idx) == 0:\n",
        "        continue\n",
        "\n",
        "      # TODO: Extract mini-batches for obs, acts, advantages, old_logp, V_target\n",
        "      mb_obs = batch_obs[idx]\n",
        "      mb_act = batch_acts[idx]\n",
        "      mb_adv = A_gae[idx]\n",
        "      mb_old_logp = old_log_prob[idx]\n",
        "      mb_V_target = V_target[idx]\n",
        "\n",
        "\n",
        "      # TODO: Actor update\n",
        "      # Hint: Use get_actor_loss with mini-batch data\n",
        "      # TODO: Add gradient clipping: nn.utils.clip_grad_norm_(actor.parameters(), 0.5)\n",
        "      actor_optimizer.zero_grad()\n",
        "      actor_loss = get_actor_loss(mb_obs,mb_act,mb_adv,mb_old_logp,beta=beta)\n",
        "      actor_loss.backward()\n",
        "      nn.utils.clip_grad_norm_(actor.parameters(), 0.5)\n",
        "      actor_optimizer.step()\n",
        "\n",
        "      # TODO: Critic update\n",
        "      # Hint: Use mse loss with critic predictions and V_target\n",
        "      # Hint: Use .flatten() instead of .squeeze() for robust handling\n",
        "      # TODO: Add gradient clipping: nn.utils.clip_grad_norm_(critic.parameters(), 0.5)\n",
        "      critic_optimizer.zero_grad()\n",
        "      critic_loss = mse(critic(mb_obs).flatten(), mb_V_target.flatten())\n",
        "      critic_loss.backward()\n",
        "      nn.utils.clip_grad_norm_(critic.parameters(), 0.5)\n",
        "      critic_optimizer.step()\n",
        "\n",
        "    return batch_rets, batch_lens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL14jbtRSi6h"
      },
      "source": [
        "# EXERCISE 4: Modify the training cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCohrMsQri2a"
      },
      "source": [
        "Add PPO-specific hyperparameters and adjust the setup.\n",
        "\n",
        "Changes needed:\n",
        "1. Add: clip_ratio, n_ppo_epochs, mini_batch_size, beta\n",
        "2. Remove: n_critic_updates (no longer separate)\n",
        "3. Everything else stays the same!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MFIvWyc3vOG4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:20<00:00,  2.02s/it, avg_ret=-143, avg_len=123]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "env_name='LunarLander-v3'\n",
        "hidden_sizes=[64, 64]\n",
        "lr=3e-4\n",
        "lr_critic=1e-3\n",
        "epochs=10\n",
        "batch_size=5_000\n",
        "gamma=0.99\n",
        "# TODO: remove n_critic_updates\n",
        "lam=0.95\n",
        "plot=True\n",
        "# TODO: Add hyperparameters\n",
        "clip_ratio = 0.2\n",
        "n_ppo_epochs = 10\n",
        "mini_batch_size = 128\n",
        "beta = 0.0 \n",
        "\n",
        "env = gym.make(env_name, continuous=True) if env_name == \"LunarLander-v3\" else gym.make(env_name)  # BipedalWalker is continuous per default\n",
        "\n",
        "obs_dim = env.observation_space.shape[0]\n",
        "n_acts = env.action_space.shape[0]\n",
        "\n",
        "actor = mlp([obs_dim]+hidden_sizes+[2*n_acts])  # output-layer: 2*n_acts, for mean and logstd as the policy is stochastic\n",
        "critic = mlp([obs_dim]+hidden_sizes+[1])\n",
        "actor_optimizer = Adam(actor.parameters(), lr=lr)\n",
        "critic_optimizer = Adam(critic.parameters(), lr=lr_critic)\n",
        "mse = nn.MSELoss()\n",
        "\n",
        "returns = []\n",
        "std = []\n",
        "\n",
        "# training loop\n",
        "progress_bar = tqdm(range(1, epochs+1))\n",
        "for _ in progress_bar:\n",
        "  batch_rets, batch_lens = train_one_epoch()\n",
        "  avg_ret = np.mean(batch_rets)\n",
        "  avg_len = np.mean(batch_lens)\n",
        "  returns.append(avg_ret)\n",
        "  std.append(np.std(batch_rets))\n",
        "  progress_bar.set_postfix({\"avg_ret\": f\"{avg_ret:5.0f}\", \"avg_len\": f\"{avg_len:5.0f}\"})\n",
        "\n",
        "if plot:\n",
        "  plt.plot(returns)\n",
        "  plt.fill_between(range(len(returns)), np.array(returns) - np.array(std), np.minimum(300, np.array(returns) + np.array(std)), alpha=0.3)\n",
        "  plt.grid()\n",
        "  goal = {\"LunarLander-v3\": 200, \"BipedalWalker-v3\": 300}.get(env_name, 0)\n",
        "  plt.axhline(goal, color='r', linestyle='--')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('average return')\n",
        "  timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "  # TODO: Change filename\n",
        "  plt.savefig(f\"PPO_training_{timestamp}.png\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0vrcXPde4Tcs",
        "7CQCDS-pTWa8",
        "swI8tn4Z4jgh",
        "h2ADMYKA4vmK",
        "6gUrD7azUQ9J",
        "UR3xJqSvU73y",
        "lGWninDCVNJH",
        "sQcwOGwq3iu2",
        "AKMwBRCmTBSm",
        "Cd8wVqKNTGuy",
        "3bao0HIiTKyq",
        "dL14jbtRSi6h"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
