{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peBdzOG_7pwy"
      },
      "source": [
        "# **RL In-Class Exercises Tutorial 1**\n",
        "This notebook contains the in-class exercises from tutorial 1 of Deep Reinforcement Learning in AML."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDG4E8Ve77N3"
      },
      "source": [
        "# SETUP - Run this cell first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mSGBE8UG8BCl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Setup complete! Ready to start exercises.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions.normal import Normal\n",
        "import numpy as np\n",
        "from typing import Sequence\n",
        "\n",
        "def mlp(sizes: Sequence[int], activation=nn.ReLU, output_activation=nn.Identity) -> nn.Sequential:\n",
        "  \"\"\"\n",
        "  Create a simple feedforward neural network.\n",
        "\n",
        "  Args:\n",
        "      sizes: List of layer sizes [input_dim, hidden1, hidden2, ..., output_dim]\n",
        "      activation: Activation function for hidden layers\n",
        "      output_activation: Activation function for output layer\n",
        "\n",
        "  Returns:\n",
        "      nn.Sequential: The neural network\n",
        "  \"\"\"\n",
        "  layers = []\n",
        "  for j in range(len(sizes)-1):\n",
        "    act = activation if j < len(sizes)-2 else output_activation\n",
        "    layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
        "  return nn.Sequential(*layers)\n",
        "\n",
        "print(\"âœ“ Setup complete! Ready to start exercises.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bNcy5MYPr4b"
      },
      "source": [
        "# EXERCISE 1: Implement discounted_return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXQM7PtrPzcC"
      },
      "source": [
        "## TODO: Implement discounted_return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Weight current reward t more than future ones because the more t enlarges, le smaller lambda will be given that it is between 0 and 1 and as t increases, so does it power.\n",
        "\n",
        "Implementation wants this :\n",
        "j = 1\n",
        "R_t = r_t + gamma^j * r_t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "orK9kU82QSrq"
      },
      "outputs": [],
      "source": [
        "def discounted_return(arr: Sequence[float], gamma: float = 0.99) -> list[float]:\n",
        "    \"\"\"\n",
        "    Compute the discounted return (rewards-to-go) for a single episode.\n",
        "\n",
        "    This computes the sum of future discounted rewards from each timestep.\n",
        "    For example, at timestep t: R_t = r_t + gamma*r_{t+1} + gamma^2*r_{t+2} + ...\n",
        "\n",
        "    Args:\n",
        "        arr: Sequence of rewards for one episode, e.g. [r_0, r_1, r_2, ..., r_T]\n",
        "        gamma: Discount factor in (0, 1]\n",
        "\n",
        "    Returns:\n",
        "        List of discounted returns, same length as arr\n",
        "    \"\"\"\n",
        "    R_t = []\n",
        "    for i in range(len(arr)):\n",
        "        sum = 0\n",
        "        power = 1\n",
        "        for j in range(i, len(arr)):\n",
        "            if j == i :\n",
        "                sum += arr[j]\n",
        "            else:\n",
        "                sum += gamma**power *arr[j]\n",
        "                power += 1\n",
        "        R_t.append(sum)\n",
        "    return R_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG2QLtq-QX33"
      },
      "source": [
        "## Test Functions (Feel free to collapse this cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "OooJyUflQbIQ"
      },
      "outputs": [],
      "source": [
        "def test_discounted_return(discounted_return_fn):\n",
        "    \"\"\"\n",
        "    Test the discounted_return implementation.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    # Test 1: Output is a list\n",
        "    try:\n",
        "        rewards = [1.0, 2.0, 3.0]\n",
        "        returns = discounted_return_fn(rewards, gamma=0.99)\n",
        "\n",
        "        if isinstance(returns, list):\n",
        "            print(\"âœ“ Test 1: Output is a list\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(f\"âœ— Test 1: Output should be a list\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 1: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    # Test 2: Output length matches input length\n",
        "    try:\n",
        "        for length in [1, 5, 10, 100]:\n",
        "            rewards = [1.0] * length\n",
        "            returns = discounted_return_fn(rewards, gamma=0.99)\n",
        "\n",
        "            if len(returns) != length:\n",
        "                print(f\"âœ— Test 2: Length mismatch for input length {length}\")\n",
        "                results.append(False)\n",
        "                break\n",
        "        else:\n",
        "            print(\"âœ“ Test 2: Output length matches input length\")\n",
        "            results.append(True)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 2: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    # Test 3: Output elements are floats\n",
        "    try:\n",
        "        rewards = [1.0, 2.0, 3.0]\n",
        "        returns = discounted_return_fn(rewards, gamma=0.99)\n",
        "\n",
        "        if all(isinstance(x, float) for x in returns):\n",
        "            print(\"âœ“ Test 3: Output elements are floats\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(\"âœ— Test 3: Output elements should be floats\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 3: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    # Test 4: Last element equals last reward\n",
        "    try:\n",
        "        rewards = [1.0, 2.0, 3.0, 5.0]\n",
        "        returns = discounted_return_fn(rewards, gamma=0.99)\n",
        "\n",
        "        if abs(returns[-1] - rewards[-1]) < 1e-6:\n",
        "            print(\"âœ“ Test 4: Last element equals last reward\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(\"âœ— Test 4: Last element should equal last reward\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 4: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    # Test 5: Simple numerical correctness\n",
        "    try:\n",
        "        # With gamma=0.9 and rewards [1, 1, 1]:\n",
        "        # returns = [1 + 0.9*1 + 0.81*1, 1 + 0.9*1, 1] = [2.71, 1.9, 1.0]\n",
        "        rewards = [1.0, 1.0, 1.0]\n",
        "        returns = discounted_return_fn(rewards, gamma=0.9)\n",
        "        expected = [2.71, 1.9, 1.0]\n",
        "\n",
        "        if all(abs(returns[i] - expected[i]) < 0.01 for i in range(len(returns))):\n",
        "            print(\"âœ“ Test 5: Numerical correctness\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(\"âœ— Test 5: Numerical values incorrect\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 5: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    # Test 6: Different gamma values work\n",
        "    try:\n",
        "        rewards = [1.0, 2.0, 3.0]\n",
        "        returns1 = discounted_return_fn(rewards, gamma=0.9)\n",
        "        returns2 = discounted_return_fn(rewards, gamma=0.5)\n",
        "\n",
        "        # With different gammas, returns should be different\n",
        "        if returns1 != returns2:\n",
        "            print(\"âœ“ Test 6: Different gamma values produce different results\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(\"âœ— Test 6: Different gammas should produce different results\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 6: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    return sum(results), len(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z28_AoIvQg_h"
      },
      "source": [
        "## Run Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ZqlosyGWQmEB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Test 1: Output is a list\n",
            "âœ“ Test 2: Output length matches input length\n",
            "âœ“ Test 3: Output elements are floats\n",
            "âœ“ Test 4: Last element equals last reward\n",
            "âœ“ Test 5: Numerical correctness\n",
            "âœ“ Test 6: Different gamma values produce different results\n",
            "\n",
            "==================================================\n",
            "Results: 6/6 tests passed\n",
            "ðŸŽ‰ All tests passed! You're ready to move on.\n"
          ]
        }
      ],
      "source": [
        "# Run the tests for discounted_return\n",
        "passed, total = test_discounted_return(discounted_return)\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"Results: {passed}/{total} tests passed\")\n",
        "if passed == total:\n",
        "  print(\"ðŸŽ‰ All tests passed! You're ready to move on.\")\n",
        "else:\n",
        "  print(\"âš ï¸  Some tests failed. Review your implementation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyVYkEjh8GEB"
      },
      "source": [
        "# EXERCISE 2: Implement compute_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGQHv3JR8I0L"
      },
      "source": [
        "## Helper function for Exercise 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "qq8ahODO8MS3"
      },
      "outputs": [],
      "source": [
        "def get_policy(obs: torch.Tensor) -> Normal:\n",
        "  \"\"\"\n",
        "  Simplified policy that returns a random Normal distribution.\n",
        "  This is a placeholder - you'll implement the real version in a later exercise.\n",
        "\n",
        "  Args:\n",
        "      obs: Observation tensor of shape (batch_size, obs_dim) or (obs_dim,)\n",
        "\n",
        "  Returns:\n",
        "      Normal distribution for actions\n",
        "  \"\"\"\n",
        "  obs = obs.unsqueeze(0) if obs.dim() == 1 else obs\n",
        "  batch_size = obs.shape[0]\n",
        "  n_acts = 2  # Hardcoded for this exercise\n",
        "\n",
        "  # Return random Normal distributions\n",
        "  mean = torch.randn(batch_size, n_acts)+ obs.sum() * 0.0\n",
        "  std = torch.ones(batch_size, n_acts)\n",
        "  return Normal(mean, std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaKh2UVt8RNU"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJQK_FM68T9S"
      },
      "source": [
        "## TODO: Implement compute_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "UiY10oQA8f3u"
      },
      "outputs": [],
      "source": [
        "def compute_loss(obs: torch.Tensor, act: torch.Tensor, weights: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute the REINFORCE loss for a given batch.\n",
        "\n",
        "    The loss is the negative weighted log-probability of actions.\n",
        "\n",
        "    Args:\n",
        "        obs: Observations tensor of shape (batch_size, obs_dim)\n",
        "        act: Actions tensor of shape (batch_size, n_acts)\n",
        "        weights: Weights (returns-to-go) tensor of shape (batch_size,)\n",
        "\n",
        "    Returns:\n",
        "        loss: Scalar tensor representing the negative weighted log-probability\n",
        "    \"\"\"\n",
        "    # NOTE: here we return the normal distribution given by the heper function\n",
        "    dist = get_policy(obs)\n",
        "    # NOTE: Moreover we need the log probability \n",
        "    #       Sum over the batch dimension (number of episode we run the update)\n",
        "    log_pb = dist.log_prob(act).sum(dim=-1)\n",
        "    # NOTE: Finally take the mean\n",
        "    return -(log_pb * weights).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDfgzULO8zm_"
      },
      "source": [
        "## Test Functions (Feel free to collapse this cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "OQAQwh7M85LH"
      },
      "outputs": [],
      "source": [
        "def test_compute_loss(compute_loss_fn):\n",
        "    \"\"\"\n",
        "    Test the compute_loss implementation.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    # Test 1: Output is a scalar\n",
        "    try:\n",
        "        obs = torch.randn(10, 8)\n",
        "        act = torch.randn(10, 2)\n",
        "        weights = torch.randn(10)\n",
        "        loss = compute_loss_fn(obs, act, weights)\n",
        "\n",
        "        if loss.shape == torch.Size([]):\n",
        "            print(\"âœ“ Test 1: Output is scalar\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(f\"âœ— Test 1: Output should be scalar, got shape {loss.shape}\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 1: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    # Test 2: Output dtype is correct\n",
        "    try:\n",
        "        obs = torch.randn(10, 8)\n",
        "        act = torch.randn(10, 2)\n",
        "        weights = torch.randn(10)\n",
        "        loss = compute_loss_fn(obs, act, weights)\n",
        "\n",
        "        if loss.dtype == torch.float32:\n",
        "            print(\"âœ“ Test 2: Output dtype is correct\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(f\"âœ— Test 2: Output dtype should be float32, got {loss.dtype}\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 2: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    # Test 3: Works with different batch sizes\n",
        "    try:\n",
        "        torch.manual_seed(42)\n",
        "        for batch_size in [1, 10, 100]:\n",
        "            obs = torch.randn(batch_size, 8)\n",
        "            act = torch.randn(batch_size, 2)\n",
        "            weights = torch.randn(batch_size)\n",
        "            loss = compute_loss_fn(obs, act, weights)\n",
        "\n",
        "            if loss.shape != torch.Size([]):\n",
        "                print(f\"âœ— Test 3: Failed for batch_size={batch_size}\")\n",
        "                results.append(False)\n",
        "                break\n",
        "        else:\n",
        "            print(\"âœ“ Test 3: Works with different batch sizes\")\n",
        "            results.append(True)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 3: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    # Test 4: Different weights produce different losses\n",
        "    try:\n",
        "        torch.manual_seed(42)\n",
        "        obs = torch.randn(10, 8)\n",
        "        act = torch.randn(10, 2)\n",
        "        weights1 = torch.ones(10)\n",
        "        weights2 = torch.ones(10) * 2\n",
        "\n",
        "        loss1 = compute_loss_fn(obs, act, weights1)\n",
        "        loss2 = compute_loss_fn(obs, act, weights2)\n",
        "\n",
        "        if not torch.isclose(loss1, loss2):\n",
        "            print(\"âœ“ Test 4: Different weights produce different losses\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(\"âœ— Test 4: Different weights should produce different losses\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 4: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    # Test 5: Gradient flow works\n",
        "    try:\n",
        "        obs = torch.randn(10, 8, requires_grad=True)\n",
        "        act = torch.randn(10, 2)\n",
        "        weights = torch.randn(10)\n",
        "\n",
        "        loss = compute_loss_fn(obs, act, weights)\n",
        "        loss.backward()\n",
        "\n",
        "        if obs.grad is not None:\n",
        "            print(\"âœ“ Test 5: Gradient flow works\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(\"âœ— Test 5: Gradients not computed\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 5: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    return sum(results), len(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtNI6Zv889OG"
      },
      "source": [
        "## Run Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "pE_D-AVe9BKF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Test 1: Output is scalar\n",
            "âœ“ Test 2: Output dtype is correct\n",
            "âœ“ Test 3: Works with different batch sizes\n",
            "âœ“ Test 4: Different weights produce different losses\n",
            "âœ“ Test 5: Gradient flow works\n",
            "\n",
            "==================================================\n",
            "Results: 5/5 tests passed\n",
            "ðŸŽ‰ All tests passed! You're ready to move on.\n"
          ]
        }
      ],
      "source": [
        "# Run the tests for compute_loss\n",
        "passed, total = test_compute_loss(compute_loss)\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"Results: {passed}/{total} tests passed\")\n",
        "if passed == total:\n",
        "  print(\"ðŸŽ‰ All tests passed! You're ready to move on.\")\n",
        "else:\n",
        "  print(\"âš ï¸  Some tests failed. Review your implementation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW3Tc2ET9N8m"
      },
      "source": [
        "# EXERCISE 3: Implement get_policy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuH5vZmL9UtN"
      },
      "source": [
        "## Setup for Exercise 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "dr28NwZ-9V4i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Policy network created with architecture: 8 -> [64, 64] -> 4\n"
          ]
        }
      ],
      "source": [
        "obs_dim = 8   # LunarLander observation dimension\n",
        "n_acts = 2    # LunarLander action dimension\n",
        "hidden_sizes = [64, 64]\n",
        "\n",
        "# Create the policy network\n",
        "policy_net = mlp([obs_dim] + hidden_sizes + [2*n_acts])\n",
        "\n",
        "print(f\"Policy network created with architecture: {obs_dim} -> {hidden_sizes} -> {2*n_acts}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHK3LxGr9fX8"
      },
      "source": [
        "## TODO: Implement get_policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "J65e71CJ9cht"
      },
      "outputs": [],
      "source": [
        "def get_policy(obs: torch.Tensor) -> Normal:\n",
        "    \"\"\"\n",
        "    Get the stochastic policy for a given observation (or batch of observations).\n",
        "\n",
        "    The policy network outputs 2*n_acts values: mean and log_std for each action dimension.\n",
        "    You need to:\n",
        "    1. Handle single observations (add batch dimension if needed)\n",
        "    2. Pass observations through the policy network\n",
        "    3. Split the output into mean and log_std\n",
        "    4. Clamp log_std to [-20, 2] for numerical stability\n",
        "    5. Return a Normal distribution with mean and exp(log_std)\n",
        "\n",
        "    Args:\n",
        "        obs: Observation tensor of shape (obs_dim,) or (batch_size, obs_dim)\n",
        "\n",
        "    Returns:\n",
        "        Normal distribution for actions with shape (batch_size, n_acts)\n",
        "    \"\"\"\n",
        "    # NOTE: this ensures obs is a tuple of 2 elems\n",
        "    obs = obs.unsqueeze(0) if obs.dim() == 1 else obs\n",
        "    batch_size = obs.shape[0]\n",
        "\n",
        "    # NOTE: Pass obs through the policy network, to do this we need to pass a tensor through the network\n",
        "    logits = policy_net(obs)\n",
        "\n",
        "    # NOTE:Split output into mean and log_std\n",
        "    mean = logits[:,:n_acts]\n",
        "    log_stds = logits[:,n_acts:]\n",
        "\n",
        "    # NOTE: clamp for numerical stability\n",
        "    log_stds = torch.clamp(log_stds, min=-20, max = 2)\n",
        "\n",
        "    return Normal(mean, torch.exp(log_stds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuzkHCHN9qCa"
      },
      "source": [
        "## Test Functions (Feel free to collapse this cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "NypmiPUj9tTI"
      },
      "outputs": [],
      "source": [
        "def test_get_policy(get_policy_fn):\n",
        "    \"\"\"\n",
        "    Test the get_policy implementation.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    # Test 1: Returns a Normal distribution\n",
        "    try:\n",
        "        obs = torch.randn(8)\n",
        "        dist = get_policy_fn(obs)\n",
        "\n",
        "        if isinstance(dist, Normal):\n",
        "            print(\"âœ“ Test 1: Returns a Normal distribution\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(f\"âœ— Test 1: Should return Normal distribution, got {type(dist)}\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 1: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    # Test 2: Mean has correct shape (single observation)\n",
        "    try:\n",
        "        obs = torch.randn(8)\n",
        "        dist = get_policy_fn(obs)\n",
        "\n",
        "        if dist.mean.shape == torch.Size([1, 2]):\n",
        "            print(\"âœ“ Test 2: Mean has correct shape for single observation\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(f\"âœ— Test 2: Mean shape should be (1, 2), got {dist.mean.shape}\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 2: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    # Test 3: Std has correct shape (single observation)\n",
        "    try:\n",
        "        obs = torch.randn(8)\n",
        "        dist = get_policy_fn(obs)\n",
        "\n",
        "        if dist.stddev.shape == torch.Size([1, 2]):\n",
        "            print(\"âœ“ Test 3: Std has correct shape for single observation\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(f\"âœ— Test 3: Std shape should be (1, 2), got {dist.stddev.shape}\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 3: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    # Test 4: Works with batch of observations\n",
        "    try:\n",
        "        obs_batch = torch.randn(10, 8)\n",
        "        dist = get_policy_fn(obs_batch)\n",
        "\n",
        "        if dist.mean.shape == torch.Size([10, 2]) and dist.stddev.shape == torch.Size([10, 2]):\n",
        "            print(\"âœ“ Test 4: Works with batch of observations\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(f\"âœ— Test 4: Shapes should be (10, 2), got mean: {dist.mean.shape}, std: {dist.stddev.shape}\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 4: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    # Test 5: Std values are positive\n",
        "    try:\n",
        "        obs = torch.randn(8)\n",
        "        dist = get_policy_fn(obs)\n",
        "\n",
        "        if torch.all(dist.stddev > 0):\n",
        "            print(\"âœ“ Test 5: Std values are positive\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(\"âœ— Test 5: Std values should be positive\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 5: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    # Test 6: Std values are reasonable (clamping works)\n",
        "    try:\n",
        "        # Create observation that might produce extreme log_std values\n",
        "        obs = torch.randn(8) * 100\n",
        "        dist = get_policy_fn(obs)\n",
        "\n",
        "        # Check if std is within reasonable bounds (exp(-20) to exp(2))\n",
        "        min_std = torch.exp(torch.tensor(-20.0))\n",
        "        max_std = torch.exp(torch.tensor(2.0))\n",
        "\n",
        "        if torch.all(dist.stddev >= min_std - 0.01) and torch.all(dist.stddev <= max_std + 0.01):\n",
        "            print(\"âœ“ Test 6: Std clamping works correctly\")\n",
        "            results.append(True)\n",
        "        else:\n",
        "            print(\"âœ— Test 6: Std clamping might not be working\")\n",
        "            results.append(False)\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Test 6: Error - {type(e).__name__}\")\n",
        "        results.append(False)\n",
        "\n",
        "    return sum(results), len(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_mNnR4A9wpu"
      },
      "source": [
        "## Run Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "Gk-qjZq990iR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Test 1: Returns a Normal distribution\n",
            "âœ“ Test 2: Mean has correct shape for single observation\n",
            "âœ“ Test 3: Std has correct shape for single observation\n",
            "âœ“ Test 4: Works with batch of observations\n",
            "âœ“ Test 5: Std values are positive\n",
            "âœ“ Test 6: Std clamping works correctly\n",
            "\n",
            "==================================================\n",
            "Results: 6/6 tests passed\n",
            "ðŸŽ‰ All tests passed! You're ready to move on.\n"
          ]
        }
      ],
      "source": [
        "# Run the tests for get_policy\n",
        "passed, total = test_get_policy(get_policy)\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"Results: {passed}/{total} tests passed\")\n",
        "if passed == total:\n",
        "  print(\"ðŸŽ‰ All tests passed! You're ready to move on.\")\n",
        "else:\n",
        "  print(\"âš ï¸  Some tests failed. Review your implementation.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bDG4E8Ve77N3",
        "-bNcy5MYPr4b",
        "SXQM7PtrPzcC",
        "RG2QLtq-QX33",
        "z28_AoIvQg_h",
        "OyVYkEjh8GEB",
        "cGQHv3JR8I0L",
        "cJQK_FM68T9S",
        "aDfgzULO8zm_",
        "mtNI6Zv889OG",
        "qW3Tc2ET9N8m",
        "ZuH5vZmL9UtN",
        "dHK3LxGr9fX8",
        "vuzkHCHN9qCa",
        "Y_mNnR4A9wpu"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
